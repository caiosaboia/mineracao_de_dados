{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Exercicio 2\"\n",
        "subtitle: \"Mineração de Dados\"\n",
        "author: \"Caio Rubem Saboia Monteiro\"\n",
        "# date: \"dd/mm/aaaa\" #if necessary\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "    # toc-location: right-body\n",
        "    code-fold: false\n",
        "    # css: styles.css #if necessary\n",
        "    math: mathjax\n",
        "\n",
        "  pdf:\n",
        "    number-sections: true\n",
        "    toc: true\n",
        "    keep_tex: true\n",
        "\n",
        "latex-engine: xelatex\n",
        "\n",
        "header-includes:\n",
        "  - \\usepackage{amsmath}\n",
        "  - \\usepackage{amsfonts}\n",
        "  - \\usepackage{amssymb}\n",
        "  - \\usepackage{listings}\n",
        "\n",
        "execute:\n",
        "  cache: true\n",
        "  enabled: true\n",
        "  freeze: true #can be use 'false' or auto\n",
        "  echo: true\n",
        "  # daemon: false #default is 300, but can use boleean values too \n",
        "\n",
        "#python\n",
        "jupyter: python3 #can be use for Julia too\n",
        "  # or can be use something like this:\n",
        "# kernelspec:\n",
        "#     name: \"xpython\"\n",
        "#     language: \"python\"\n",
        "#     display_name: \"Python 3.7 (XPython)\"\n",
        "\n",
        "#R\n",
        "# knitr:\n",
        "#   opts_chunk:\n",
        "#     collapse: true\n",
        "#     comment: \">>\"\n",
        "#     R.options:\n",
        "#       knitr.graphics.auto_pdf: true\n",
        "\n",
        "# engine: julia # for more aplicatoins use quarto.org or :QuartoHelp Julia\n",
        "---\n",
        "\n",
        "\n",
        "Aplicando modelos avançados de aprendizado supervisionado\n",
        "\n",
        "\n",
        "# MNIST - Reconhecimento de algarismos escritos a mão\n"
      ],
      "id": "16c78b8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# 1. Carregar o conjunto de dados MNIST\n",
        "data = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
        "\n",
        "# 2. Normalizar os dados (0-255 -> 0-1)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 3. Definir a arquitetura da rede neural\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),  # Achatar imagens 28x28 para vetor 784\n",
        "    keras.layers.Dense(70, activation='relu'),  # Camada oculta com 128 neurônios\n",
        "    keras.layers.Dense(10, activation='softmax') # Camada de saída para 10 classes\n",
        "])\n",
        "\n",
        "# 4. Compilar o modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "id": "89bbd2cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5. Treinar o modelo\n",
        "epochs = 20  # Número de épocas\n",
        "history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "# 6. Avaliação no conjunto de teste\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Perda: {loss:.4f}, Acurácia: {accuracy:.4f}')"
      ],
      "id": "3c8a19a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 7. Exemplo de previsão\n",
        "predictions = model.predict(x_test)\n",
        "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
        "plt.title(f'Predição: {np.argmax(predictions[0])}')\n",
        "plt.show()\n",
        "\n",
        "# 8. Visualizar erros do modelo\n",
        "# 9. Sortear várias imagens aleatórias e verificar as predições\n",
        "random_indices = random.sample(range(len(x_test)), 10)\n",
        "predictions_list = [np.argmax(predictions[idx]) for idx in random_indices]\n",
        "real_values_list = [y_test[idx] for idx in random_indices]\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    if predictions_list[i] == real_values_list[i]:\n",
        "        print(f\"acertou\")\n",
        "    else:\n",
        "        print(f\"errou\")"
      ],
      "id": "36b330d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comentários da Google Store\n"
      ],
      "id": "64bfde54"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Carregar o CSV\n",
        "df = pd.read_csv('data/googlestore.csv')  # Ajuste o caminho se necessário\n",
        "\n",
        "# Verificar estrutura dos dados\n",
        "print(df.head())"
      ],
      "id": "bcbb2bc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "\n",
        "stop_words = stopwords.words('portuguese')\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-záéíóúâêîôûãõç\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['clean_text'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "df = df[df['clean_text'].str.strip() != '']"
      ],
      "id": "42986074",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df['clean_text']).toarray()\n",
        "y = df['sentiment_polarity']"
      ],
      "id": "e2ffeef7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "id": "daaf5775",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "model.fit(X_train, y_train)"
      ],
      "id": "c41599b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Obter as classes únicas (para os rótulos)\n",
        "unique_labels = sorted(df['sentiment_polarity'].unique())\n",
        "\n",
        "# Plotar a matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Matriz de Confusão', fontsize=14)\n",
        "plt.colorbar()\n",
        "\n",
        "# Adicionar rótulos\n",
        "tick_marks = np.arange(len(unique_labels))\n",
        "plt.xticks(tick_marks, unique_labels, rotation=45)\n",
        "plt.yticks(tick_marks, unique_labels)\n",
        "\n",
        "# Preencher com os valores\n",
        "thresh = cm.max() / 2.0\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 ha=\"center\", va=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.ylabel('Rótulo Verdadeiro', fontsize=12)\n",
        "plt.xlabel('Previsão do Modelo', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "ce58c1ac",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\cocad\\miniconda3\\envs\\tensorflow_env\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}